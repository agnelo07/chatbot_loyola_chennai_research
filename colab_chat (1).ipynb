{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWq3kAXcOe3C"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg0noVS0cZ3f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    split sentence into array of words/tokens\n",
        "    a token can be a word or punctuation character, or number\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY0X26yZceM-"
      },
      "outputs": [],
      "source": [
        "def stem(word):\n",
        "    \"\"\"\n",
        "    stemming = find the root form of the word\n",
        "    examples:\n",
        "    words = [\"organize\", \"organizes\", \"organizing\"]\n",
        "    words = [stem(w) for w in words]\n",
        "    -> [\"organ\", \"organ\", \"organ\"]\n",
        "    \"\"\"\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFygshmdciWO"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(tokenized_sentence, words):\n",
        "    \"\"\"\n",
        "    return bag of words array:\n",
        "    1 for each known word that exists in the sentence, 0 otherwise\n",
        "    example:\n",
        "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
        "    \"\"\"\n",
        "    # stem each word\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    # initialize bag with 0 for each word\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, w in enumerate(words):\n",
        "        if w in sentence_words: \n",
        "            bag[idx] = 1\n",
        "\n",
        "    return bag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK3jR0k1oAXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13f881a-6a95-4490-e064-9fe17546baf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sISKM-K_PREY"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/intents.json') as file:\n",
        "  data=json.load(file)\n",
        "training_sentences=[]\n",
        "training_labels=[]\n",
        "labels=[]\n",
        "responses=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7Gb2v4eUKEZ"
      },
      "outputs": [],
      "source": [
        "for intent in data['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    training_sentences.append(pattern)\n",
        "    training_labels.append(intent['tag'])\n",
        "  responses.append(intent['responses'])\n",
        "  if intent['tag'] not in labels:\n",
        "    labels.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4a2-fNtUQJa"
      },
      "outputs": [],
      "source": [
        "num_classes=len(labels)\n",
        "lbl_encoder=LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "training_labels=lbl_encoder.transform(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xfopkweXhO9"
      },
      "outputs": [],
      "source": [
        "vocab_size=1000\n",
        "embedding_dim=16\n",
        "max_len=20\n",
        "oov_token=\"<OOV>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS0wf5wsX7Bn"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer(num_words=vocab_size,oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index=tokenizer.word_index\n",
        "sequences=tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences=pad_sequences(sequences,truncating='post',maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x9CZ7v0bYvD"
      },
      "outputs": [],
      "source": [
        "#Model training\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,embedding_dim,input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(num_classes,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0IdSloHb-9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a8eb65-dc6b-4581-9a88-0a9eb8543aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 16)            16000     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 16)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 37)                629       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,173\n",
            "Trainable params: 17,173\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL4L6yvtcaxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5245cd0-e44b-4ed5-82f9-d318b59d26d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 2ms/step - loss: 3.6118 - accuracy: 0.0336\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.6077 - accuracy: 0.0616\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.6046 - accuracy: 0.0616\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.6014 - accuracy: 0.0616\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5984 - accuracy: 0.0616\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5947 - accuracy: 0.0616\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5902 - accuracy: 0.0616\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5851 - accuracy: 0.0616\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5789 - accuracy: 0.0616\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5714 - accuracy: 0.0616\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5618 - accuracy: 0.0616\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5509 - accuracy: 0.0616\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5385 - accuracy: 0.0616\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5248 - accuracy: 0.0616\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.5105 - accuracy: 0.0616\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4952 - accuracy: 0.0616\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.4813 - accuracy: 0.0616\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.4619 - accuracy: 0.0616\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.4480 - accuracy: 0.0616\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.4283 - accuracy: 0.0616\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.4061 - accuracy: 0.0616\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.3851 - accuracy: 0.0700\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.3618 - accuracy: 0.0728\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.3342 - accuracy: 0.0868\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3073 - accuracy: 0.1008\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.2786 - accuracy: 0.1008\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.2481 - accuracy: 0.1036\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.2189 - accuracy: 0.1008\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.1844 - accuracy: 0.1064\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.1487 - accuracy: 0.1036\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.1114 - accuracy: 0.1036\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.0760 - accuracy: 0.1036\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.0402 - accuracy: 0.1232\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.0052 - accuracy: 0.1289\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.9644 - accuracy: 0.1485\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9247 - accuracy: 0.1569\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.8913 - accuracy: 0.1737\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.8555 - accuracy: 0.1765\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.8240 - accuracy: 0.1933\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7893 - accuracy: 0.1933\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.7596 - accuracy: 0.1961\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.7302 - accuracy: 0.1961\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.6973 - accuracy: 0.2101\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.6673 - accuracy: 0.2129\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.6415 - accuracy: 0.2157\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.6053 - accuracy: 0.2269\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5720 - accuracy: 0.2381\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5435 - accuracy: 0.2269\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5106 - accuracy: 0.2465\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.4779 - accuracy: 0.2745\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.4496 - accuracy: 0.2829\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.4171 - accuracy: 0.3025\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.3834 - accuracy: 0.3165\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.3526 - accuracy: 0.3193\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.3226 - accuracy: 0.3445\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.2925 - accuracy: 0.3473\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.2584 - accuracy: 0.3782\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.2259 - accuracy: 0.4062\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.1902 - accuracy: 0.4314\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.1605 - accuracy: 0.4482\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.1282 - accuracy: 0.4314\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.0896 - accuracy: 0.4678\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.0540 - accuracy: 0.4762\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.0191 - accuracy: 0.4818\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.9840 - accuracy: 0.4818\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.9494 - accuracy: 0.5154\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.9140 - accuracy: 0.5210\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8776 - accuracy: 0.5238\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8410 - accuracy: 0.5462\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.8011 - accuracy: 0.5658\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.7667 - accuracy: 0.5770\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.7325 - accuracy: 0.5322\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6923 - accuracy: 0.5994\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6584 - accuracy: 0.6218\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.6206 - accuracy: 0.6134\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5836 - accuracy: 0.6190\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5485 - accuracy: 0.6331\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5111 - accuracy: 0.6471\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4764 - accuracy: 0.6443\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4418 - accuracy: 0.6583\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4092 - accuracy: 0.6695\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3752 - accuracy: 0.6947\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3450 - accuracy: 0.7031\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3117 - accuracy: 0.7283\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2798 - accuracy: 0.7171\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2463 - accuracy: 0.7283\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2260 - accuracy: 0.7227\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2079 - accuracy: 0.7703\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1733 - accuracy: 0.7507\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1466 - accuracy: 0.7843\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1111 - accuracy: 0.7843\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0857 - accuracy: 0.7703\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0687 - accuracy: 0.7899\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.7843\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0184 - accuracy: 0.7843\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9985 - accuracy: 0.7899\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9755 - accuracy: 0.8011\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9537 - accuracy: 0.8207\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9291 - accuracy: 0.8151\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9164 - accuracy: 0.8207\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8923 - accuracy: 0.8291\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.8403\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8456 - accuracy: 0.8403\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8306 - accuracy: 0.8403\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8142 - accuracy: 0.8403\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7974 - accuracy: 0.8515\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7802 - accuracy: 0.8739\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7657 - accuracy: 0.8655\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.8627\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7267 - accuracy: 0.8768\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.8852\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.8908\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.8908\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.8936\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.8908\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.8992\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.8964\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.9076\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.9132\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.9188\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.9244\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.9160\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.9188\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.9188\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.9188\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.9356\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.9356\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.9440\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.9300\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9328\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.9440\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.9412\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.9384\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.9468\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.9524\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.9580\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.9580\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.9636\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.9608\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.9580\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.9664\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.9608\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.9636\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.9636\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.9692\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.9664\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.9636\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.9692\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.9608\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.9720\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.9608\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.9720\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.9720\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.9720\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.9720\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9664\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.9748\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9636\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9692\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9748\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9748\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9692\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9748\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9804\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9720\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9748\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9776\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9720\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9748\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9804\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9832\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9776\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9748\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9748\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9804\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9804\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9832\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9832\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9804\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9804\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9832\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9860\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9804\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9804\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9860\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9832\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9776\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9860\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9888\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9860\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9916\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9860\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9860\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9832\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9860\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9860\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9860\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9860\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9860\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9832\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9888\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9888\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9888\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9916\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9832\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9860\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9804\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9916\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9916\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9888\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9916\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9916\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9888\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9916\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9916\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9916\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9916\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9888\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9860\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9888\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9888\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.9916\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9888\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9860\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9916\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9916\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9916\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9888\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9888\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9888\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9860\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9888\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9916\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9916\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9916\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9916\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9916\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9916\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9916\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9860\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9888\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9888\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9916\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9916\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9916\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9916\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9916\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9916\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9916\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9944\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9916\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9916\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9916\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9888\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9888\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9888\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9916\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9916\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9916\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9916\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9916\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9916\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9888\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9888\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9916\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9944\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9916\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9916\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9916\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9916\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9916\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9916\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9888\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9944\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9916\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9944\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9944\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9888\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9916\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9944\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9888\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9888\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9944\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9944\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9944\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9888\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9916\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9916\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9916\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9944\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9944\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9916\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9944\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9944\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9944\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9944\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9944\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9944\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9944\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9972\n"
          ]
        }
      ],
      "source": [
        "epochs=300\n",
        "history=model.fit(padded_sequences,np.array(training_labels),epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNIQJYffdMTa"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxG_dtQWnty_"
      },
      "outputs": [],
      "source": [
        "# to save the trained model\n",
        "model.save(\"chat_model\")\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdWl2DehoDG8"
      },
      "outputs": [],
      "source": [
        "# to save the fitted tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        " pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXjIq11NheUU"
      },
      "outputs": [],
      "source": [
        "# to save the fitted label encoder\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "  pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO2TUlPOdHtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4891c759-006f-408f-ea0e-39d01da4f999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrp4WNaIdtBL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moQXgcIBd9Rl"
      },
      "outputs": [],
      "source": [
        "import colorama\n",
        "colorama.init()\n",
        "from colorama import Fore,Style,Back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvhasgVxeIae"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_yj0CJMeO9_"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/intents.json') as file:\n",
        "  data=json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFWaDNREekO5",
        "outputId": "5488d8d1-e4da-46a3-e2d0-88d4712bb5dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start messaging with the bot(type quit to stop)!\n",
            "User:hi\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "LoBot: Hello!\n",
            "User:hoe are you\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "LoBot: I'm LOBOT\n",
            "User:q\n"
          ]
        }
      ],
      "source": [
        "def chat():\n",
        "  #load trained model\n",
        "  model=keras.models.load_model('chat_model')\n",
        "  #load tokenizer object\n",
        "  with open('tokenizer.pickle','rb') as handle:\n",
        "     tokenizer=pickle.load(handle)\n",
        "  #load label encoder object\n",
        "  with open('label_encoder.pickle','rb') as enc:\n",
        "     lbl_encoder=pickle.load(enc)\n",
        "  #parameters\n",
        "  max_len=20\n",
        "  while True:\n",
        "      print(Fore.LIGHTBLUE_EX+'User:'+Style.RESET_ALL,end=\"\")\n",
        "      inp=input()\n",
        "      if inp.lower()=='q':\n",
        "        break\n",
        "      result=model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),truncating='post',maxlen=max_len))\n",
        "      tag=lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "      for i in data['intents']:\n",
        "         if i['tag']==tag:\n",
        "           print(Fore.GREEN+'LoBot:'+Style.RESET_ALL,np.random.choice(i['responses']))\n",
        "print(Fore.YELLOW+'Start messaging with the bot(type quit to stop)!'+Style.RESET_ALL)\n",
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1wVjmHHQ_Y1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}